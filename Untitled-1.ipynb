{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07ecd545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "238199ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>published</th>\n",
       "      <th>summary</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>transformer</td>\n",
       "      <td>The Xi-transform for conformally flat space-time</td>\n",
       "      <td>George Sparling</td>\n",
       "      <td>2006-12-01T03:22:29Z</td>\n",
       "      <td>The Xi-transform is a new spinor transform ari...</td>\n",
       "      <td>http://arxiv.org/abs/gr-qc/0612006v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transformer</td>\n",
       "      <td>Multiple basic hypergeometric transformation f...</td>\n",
       "      <td>Yasushi Kajihara</td>\n",
       "      <td>2013-10-08T01:59:21Z</td>\n",
       "      <td>Some multiple hypergeometric transformation fo...</td>\n",
       "      <td>http://arxiv.org/abs/1310.1984v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transformer</td>\n",
       "      <td>The Fourier and Hilbert transforms under the B...</td>\n",
       "      <td>Xing-Tang Dong, Kehe Zhu</td>\n",
       "      <td>2016-05-27T15:23:27Z</td>\n",
       "      <td>There is a canonical unitary transformation fr...</td>\n",
       "      <td>http://arxiv.org/abs/1605.08683v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>transformer</td>\n",
       "      <td>Identities for the Ln-transform, the L2n-trans...</td>\n",
       "      <td>Nese Dernek, Fatih Aylikci</td>\n",
       "      <td>2014-03-10T09:30:21Z</td>\n",
       "      <td>In the present paper, the authors introduce se...</td>\n",
       "      <td>http://arxiv.org/abs/1403.2188v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>transformer</td>\n",
       "      <td>Towards Lightweight Transformer via Group-wise...</td>\n",
       "      <td>Gen Luo, Yiyi Zhou, Xiaoshuai Sun, Yan Wang, L...</td>\n",
       "      <td>2022-04-16T11:30:26Z</td>\n",
       "      <td>Despite the exciting performance, Transformer ...</td>\n",
       "      <td>http://arxiv.org/abs/2204.07780v1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tag                                              title  \\\n",
       "0  transformer   The Xi-transform for conformally flat space-time   \n",
       "1  transformer  Multiple basic hypergeometric transformation f...   \n",
       "2  transformer  The Fourier and Hilbert transforms under the B...   \n",
       "3  transformer  Identities for the Ln-transform, the L2n-trans...   \n",
       "4  transformer  Towards Lightweight Transformer via Group-wise...   \n",
       "\n",
       "                                             authors             published  \\\n",
       "0                                    George Sparling  2006-12-01T03:22:29Z   \n",
       "1                                   Yasushi Kajihara  2013-10-08T01:59:21Z   \n",
       "2                           Xing-Tang Dong, Kehe Zhu  2016-05-27T15:23:27Z   \n",
       "3                         Nese Dernek, Fatih Aylikci  2014-03-10T09:30:21Z   \n",
       "4  Gen Luo, Yiyi Zhou, Xiaoshuai Sun, Yan Wang, L...  2022-04-16T11:30:26Z   \n",
       "\n",
       "                                             summary  \\\n",
       "0  The Xi-transform is a new spinor transform ari...   \n",
       "1  Some multiple hypergeometric transformation fo...   \n",
       "2  There is a canonical unitary transformation fr...   \n",
       "3  In the present paper, the authors introduce se...   \n",
       "4  Despite the exciting performance, Transformer ...   \n",
       "\n",
       "                                   link  \n",
       "0  http://arxiv.org/abs/gr-qc/0612006v1  \n",
       "1      http://arxiv.org/abs/1310.1984v2  \n",
       "2     http://arxiv.org/abs/1605.08683v1  \n",
       "3      http://arxiv.org/abs/1403.2188v1  \n",
       "4     http://arxiv.org/abs/2204.07780v1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"arxiv_papers.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6355b2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Xi-transform is a new spinor transform arising naturally in Einstein's general relativity. Here the example of conformally flat space-time is discussed in detail. In particular it is shown that for this case, the transform coincides with two other naturally defined transforms: one a two-variable transform on the Lie group SU(2, C), the other a transform on the space of null split octaves. The key properties of the transform are developed.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['summary'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2958a772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"The Xi-transform is a new spinor transform arising naturally in Einstein's general relativity. \n",
    "# Here the example of conformally flat space-time is discussed in detail. In particular it is shown that for this case, \n",
    "# the transform coincides with two other naturally defined transforms: one a two-variable transform on the Lie group SU(2, C), \n",
    "# the other a transform on the space of null split octaves. The key properties of the transform are developed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "885c3dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75428ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = json.load(open(\"parsed_papers.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9c2b406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['tag', 'title', 'authors', 'published', 'summary', 'link', 'pdf_link', 'id', 'introduction', 'method', 'experiment', 'results', 'conclusion'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2b4254a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'method termed the Autonomous Prompt Engi-\\nneering Toolbox (APET) has incorporated var-\\nious prompt design strategies into the prompt\\noptimization process. In APET, the LLM is\\nneeded to implicitly select and apply the appro-\\npriate strategies because prompt design strate-\\ngies can have negative effects. This implicit\\nselection may be suboptimal due to the limited\\noptimization capabilities of LLMs. This paper\\nintroduces Optimizing Prompts with sTrategy\\nSelection (OPTS), which implements explicit\\nselection mechanisms for prompt design. We\\npropose three mechanisms, including a Thomp-\\nson sampling-based approach, and integrate\\nthem into EvoPrompt, a well-known prompt\\noptimizer. Experiments optimizing prompts for\\ntwo LLMs, Llama-3-8B-Instruct and GPT-4o\\nmini, were conducted using BIG-Bench Hard.\\nOur results show that the selection of prompt\\ndesign strategies improves the performance\\nof EvoPrompt, and the Thompson sampling-\\nbased mechanism achieves the best overall re-\\nsults. Our experimental code is provided at\\nhttps://github.com/shiralab/OPTS.\\n1\\nIntroduction\\nLarge language models (LLMs) such as GPT-\\n4 (OpenAI et al., 2024), Gemini (Team et al., 2024),\\nand Llama 3 (Grattafiori et al., 2024) have demon-\\nstrated superior abilities in a variety of domains,\\nincluding medicine (Nori et al., 2023), law (Katz\\net al., 2024), and code generation (Rozière et al.,\\n2024). Since well-crafted prompts improve the\\nperformance of LLMs, prompt engineering (i.e.,\\ndesigning better prompts) plays a key role in the\\narea (Bsharat et al., 2024; Schulhoff et al., 2024).\\nDespite its importance, prompt engineering is labo-\\nrious as it requires a lot of time for refinement and\\nsufficient knowledge of the tasks. To design effec-\\ntive prompts with less effort, research on prompt\\noptimization has been actively conducted. In partic-\\nular, discrete prompt optimization, which optimizes\\nprompts within the natural language space, has at-\\ntracted attention. This approach is valuable as it\\ntypically allows for the optimization of prompts\\nfor black-box LLMs, such as GPT-4, while also\\nproviding interpretable results (Chang et al., 2024).\\nTo explore effective prompts within the large nat-\\nural language space, several methods have been\\nproposed, which include emulating evolutionary al-\\ngorithms using LLMs (Guo et al., 2024; Fernando\\net al., 2023; Cui et al., 2024). These methods have\\ndiscovered effective prompts, but they often differ\\nfrom sophisticated prompts carefully designed by\\nhuman experts.\\nPrompt design strategies, which provide guide-\\nlines for creating effective prompts, can be key\\nto boosting the performance of prompt optimiz-\\ners. In fact, Chain-of-Thought (CoT; Wei et al.,\\n2022) and Role Prompting (Wang et al., 2024a)\\nhave been employed in prompt optimization, lead-\\ning to better prompts (Agarwal et al., 2024). Re-\\ncently, Kepel and Valogianni (2024) proposed a\\nmethod termed the Autonomous Prompt Engineer-\\ning Toolbox (APET), which incorporated various\\nprompt design strategies into the optimization pro-\\ncess. APET fed all prepared strategies into an\\nLLM to generate a new prompt that incorporates\\nthe strategies. However, not all strategies should\\nbe incorporated because prompt design strategies\\ncan have negative effects depending on both the\\nLLM and the task (Zheng et al., 2024; Deng et al.,\\n2024). In APET, an LLM that generates prompts\\n1\\narXiv:2503.01163v1  [cs.AI]  3 Mar 2025\\n\\nK descriptions of prompt design strategies\\nOption not using prompt design strategies\\nMeta-prompt:\\ne.g.) Modify the prompt using prompt design strategy.\\nThe description of selected prompt design strategy \\nPrompt:\\ne.g.) Evaluate the result of a random Boolean expression.\\nModify prompt\\nModified prompt:\\ne.g.) Rephrase before responding: Evaluate the \\nresult of a random Boolean expression.\\nPrompt-designing LLM\\nThompson Sampling: Select one arm\\n+\\n+\\n……\\nArm 1\\nArm 2\\nArm K\\nArm K + 1\\nNot modify prompt\\nPrompt\\ne.g.) Evaluate the result of a random Boolean expression.\\nPrompt\\ne.g.) Evaluate the result of a random Boolean expression.\\nFigure 1: Overview of OPTS(TS), which shows how the prompt generated from the prompt optimizer is modified.\\nIf one of the first K arms is selected, the description of the prompt design strategy corresponding to the selected arm\\nis passed to the prompt-designing LLM. If the (K + 1)-th arm is selected, the prompt is not modified in any way.\\nis required to implicitly select appropriate strate-\\ngies, which may lead to suboptimal performance\\nbecause LLMs cannot perform optimization effec-\\ntively (Huang et al., 2024).\\nIn this paper, we introduce explicit selection\\nmechanisms for prompt design strategies for the\\nfirst time. We also propose three selection meth-\\nods, including one based on Thompson sampling\\n(TS; Thompson, 1933; Russo et al., 2018). By in-\\ntegrating them with the existing prompt optimizer,\\nEvoPrompt (Guo et al., 2024), we show that ex-\\nplicit strategy selection effectively leverages exist-\\ning knowledge of prompt design and enhances the\\nperformance of prompt optimizers. Moreover, the\\noptimizer with the TS-based selection mechanism\\noutperforms other existing methods.\\nIn summary, our contributions are as follows:\\n• We propose explicit prompt design strategy se-\\nlection mechanisms, including a method based\\non Thompson sampling, for prompt optimizers.\\n• We experimentally show that the proposed selec-\\ntion mechanism enhances EvoPrompt. TS-based\\nselection improves EvoPrompt’s performance by\\nup to 50% when using GPT-4o mini for both gen-\\nerating prompts and solving downstream tasks.\\n• We also compare the TS-based selection with\\nAPET-based selection and uniform sampling-\\nbased selection. The results demonstrate that\\nTS-based selection is overall superior.\\n2\\nRelated Work\\nPrompt design strategy.\\nThe term prompt de-\\nsign strategy refers to a well-established guideline\\nfor designing prompts that have been empirically\\nknown to be effective. Chain-of-Thought (CoT;\\nWei et al., 2022) and Role Prompting (Wang et al.,\\n2024a) are notable examples. CoT asks the LLMs\\nto generate not only the answer, but also the reason-\\ning process that leads to the answer. Role Prompt-\\ning is a strategy that includes phrases in the prompt\\nthat give the LLM a role. Various prompt design\\nstrategies have been proposed so far (Schulhoff\\net al., 2024; Xu et al., 2023; Li et al., 2023; Xu\\net al., 2024; Deng et al., 2024; Lu et al., 2023;\\nBsharat et al., 2024), yet they are not always useful.\\nIndeed, CoT and Role Prompting can lead to worse\\nresults (Deng et al., 2024; Zheng et al., 2024). As\\ntheir efficacy depends on the LLM and task, users\\nneed to make a non-obvious decision on whether\\nto use them.\\nDiscrete prompt optimization.\\nDiscrete prompt\\noptimization optimizes prompts in natural language\\nspace. To effectively deal with natural language\\nspace, several prompt optimizers emulate the pro-\\ncess of black-box optimization algorithms by using\\nLLMs. These methods are useful because opti-\\nmized prompts have high interpretability, while\\n2\\n\\nthey can be applied to LLMs that can be accessed\\nthrough black-box APIs such as GPT-4 (OpenAI\\net al., 2024). GRIPS (Prasad et al., 2023) repeatedly\\nedits the phrases in the prompt, and APE (Zhou\\net al., 2023) repeatedly generates prompts using\\nLLMs based on Monte Carlo search. Unlike APE\\nand GRIPS, ProTeGi (Pryzant et al., 2023) uses a\\nmechanism in which incorrect answers made by an\\nLLM and the corresponding prompt are fed into\\nanother LLM to generate a proposal to improve the\\nprompt, and another LLM responsible for design-\\ning prompts then modifies the prompt according\\nto the proposal. In addition to this mechanism,\\nPromptAgent (Wang et al., 2024b) also uses Monte\\nCarlo Tree Search to efficiently optimize prompts.\\nBesides these, adv-ICL (Long et al., 2024), which\\napplies adversarial learning, has been proposed. In\\nOPRO (Yang et al., 2024), instead of using an LLM\\nto suggest a proposal to improve the prompts, an\\nLLM directly generates new prompts using three\\nitems: previously generated prompts, their scores,\\nand a description of the downstream task.\\nRecently, several methods combining LLMs\\nwith evolutionary algorithms have been pro-\\nposed (Guo et al., 2024; Jin et al., 2024; Fernando\\net al., 2023; Cui et al., 2024). EvoPrompt (Guo\\net al., 2024), a representative method among them,\\nemulates the optimization process of Genetic Al-\\ngorithm (GA) or Differential Evolution (DE). In\\ncontrast to EvoPrompt (Guo et al., 2024), Prompt-\\nBreeder (Fernando et al., 2023) also optimizes the\\nprompt that is used for generating new prompts.\\nPhaseEvo (Cui et al., 2024) optimizes both task\\ninstruction and examples and achieves highly ef-\\nfective optimization by dividing optimization into\\nmultiple stages.\\nIn addition to dividing optimization into multi-\\nple stages, PromptWizard (Agarwal et al., 2024)\\nutilizes prompt design strategies such as CoT and\\nRole Prompting, but it lacks a strategy selection\\nmechanism and applies them in all cases. EoT\\nprompting (Jin et al., 2024) optimizes zero-shot\\nCoT (Kojima et al., 2022) using evolutionary algo-\\nrithms. APET (Kepel and Valogianni, 2024) is the\\nmost relevant to our study. In APET, a prompt and\\ndescriptions of prompt design strategies are input\\nto an LLM. The LLM then implicitly selects strate-\\ngies and generates a new prompt. In contrast, we\\npropose explicit strategy selection mechanisms that\\nassist prompt optimizers in exploiting appropriate\\nstrategies.\\n3\\nProposed Methods\\nIn this section, we describe our proposed meth-\\nods for selecting prompt design strategies. We then\\nintroduce prompt optimization algorithms that com-\\nbine EvoPrompt (Guo et al., 2024) with the strategy\\nselection methods. We term our methods Optimiz-\\ning Prompts with sTrategy Selection (OPTS).\\nTerminology\\nTask-solving LLM is an LLM that\\nis applied to and solves downstream tasks, while\\nPrompt-designing LLM is another LLM that pro-\\nduces helpful prompts for task-solving LLMs. In\\ncontrast to prompt, which represents an instruction\\nfor a task-solving LLM, meta-prompt refers to an\\ninstruction for a prompt-designing LLM.\\n3.1\\nSelection of Prompt Design Strategies\\nIn the following, we discuss three different meth-\\nods: the TS-based selection called OPTS(TS),\\nthe uniform sampling-based selection called\\nOPTS(US), and the APET-based selection called\\nOPTS(APET).\\nOPTS(TS)\\nOPTS(TS) selects prompt design\\nstrategies using Thompson sampling (TS; Thomp-\\nson, 1933; Russo et al., 2018), which is a multi-\\narmed bandit algorithm and empirically shows su-\\nperior performance (Chapelle and Li, 2011).\\nThe overview of OPTS(TS) is shown in Figure 1.\\nThere are K arms, each corresponding to one of\\nthe K descriptions of the prompt design strategies.\\nAlso, we append a special arm called the inaction\\narm, which corresponds to the option of not using\\nthe prompt design strategy, making a total of K +1\\narms. The inaction arm is needed because none of\\nthe predefined strategies may improve the prompts\\nat all. To instantiate TS, we use the beta distri-\\nbutions as priors for the expected reward. Once\\none of the first K arms is sampled by TS, we feed\\nthe description of the corresponding prompt de-\\nsign strategy into the prompt-designing LLM along\\nwith the meta-prompt and the prompt to be mod-\\nified. The LLM then modifies the prompt based\\non the input. The meta-prompt is the same as that\\nused in APET, whose details are explained in Ap-\\npendix A. After evaluating the generated prompt\\nwith the task-solving LLM and calculating its score,\\na reward is calculated using the score, and the dis-\\ntributions in TS are updated based on the reward.\\nThroughout this paper, we compute the reward r\\nfor a prompt with the score s as\\nr = 1\\nh\\ns > max ˜S\\ni\\n∈{0, 1} ,\\n(1)\\n3\\n\\nAlgorithm 1 EvoPrompt(DE)-OPTS\\nRequire: Initial prompts P0 = {p1, p2, . . . , pN}, population size N, number of iterations T, development\\nset Ddev consisting of input and correct output pairs (x, y), scoring function g, task-solving LLM fT\\n1: Evaluation of initial prompts: S0 ←\\nn\\nsi =\\n1\\n|Ddev|\\nP\\n(x,y)∈Ddev g (y, fT (pi, x)) : pi ∈P0\\no\\n2: for t = 1 to T do\\n3:\\nfor pi in Pt−1 do\\n▷pi: the i-th parent prompt\\n4:\\nSample donors: pr1, pr2 ∈Pt−1 , where pr1, pr2, and pi differ from each other.\\n5:\\nCrossover and Mutation: p′\\ni ←fD(mde, (pi, pr1, pr2, pbest))\\n6:\\nwhere pbest is the current best prompt.\\n▷fD: Prompt-Designing LLM\\n7:\\n▷mde: Meta-prompt for DE-based crossover and mutation\\n8:\\nOPTS: Generate p′′\\ni from p′\\ni by incorporating prompt design strategies (Refer to Section 3.1)\\n9:\\nSelection: p∗\\ni = argmax\\np∈{pi,p′′\\ni }\\n1\\n|Ddev|\\nP\\n(x,y)∈Ddev g (y, fT (p, x))\\n10:\\n▷Keep the better one in the population\\n11:\\nUpdate probability distribution if the TS-based selection is used (Refer to Section 3.1)\\n12:\\nend for\\n13:\\nUpdate: Pt ←{p∗\\ni : 1 ≤i ≤N}\\n14: end for\\n15: Return the best prompt p∗= argmaxp∈PT\\n1\\n|Ddev|\\nP\\n(x,y)∈Ddev g (y, fT (p, x))\\nwhere ˜S is the set of scores of the parent prompts,\\nwhich come from EvoPrompt (Guo et al., 2024)\\ndescribed in Section 3.2, and 1[ · ] is the indicator\\nfunction.\\nOPTS(US)\\nIn OPTS(US), each arm is selected\\naccording to a uniform distribution. OPTS(US) is\\nsimilar to OPTS(TS), except that the probability of\\nselecting each arm is equal and is not updated.\\nOPTS(APET)\\nOPTS(APET) is the selection\\nmethod based on APET (Kepel and Valogianni,\\n2024). It is slightly different from APET in that it\\nhas an additional option equivalent to the inaction\\narm. OPTS(APET) first randomly decides with\\na probability of 0.5 whether to modify a prompt\\nbased on the prompt design strategies. If it de-\\ncides to modify the prompt, the prompt-designing\\nLLM is applied to the prompt to incorporate the\\nprompt design strategies. The prompt-designing\\nLLM receives the meta-prompt, the description of\\nall prompt design strategies, and the prompt to be\\nmodified. Then, it implicitly selects the prompt de-\\nsign strategies and modifies the prompt according\\nto them.\\n3.2\\nEvoPrompt with OPTS\\nWe combine the proposed selection methods with\\nEvoPrompt (Guo et al., 2024). We adopt Evo-\\nPrompt because it is effective yet sufficiently sim-\\nple, allowing us to focus solely on evaluating the\\nstrategy selection methods. Also, it has variants\\ndepending on whether GA or DE is employed. This\\nfeature allows us to assess the impact of prompt\\ndesign strategy selection on different optimization\\nalgorithms. The algorithm integrated OPTS into\\nEvoPrompt(DE) is shown in Algorithm 1, while\\nthat based on EvoPrompt(GA) is shown in Ap-\\npendix B. Note that a response generation by LLM\\nf is denoted by f (p, x). We insert OPTS after the\\ncrossover and mutation process of EvoPrompt. Af-\\nter evaluating the newly generated prompts with the\\ntask-solving LLM, the scores are used to determine\\nthe next generation’s population and, if necessary,\\nto update the distribution of the arms in TS. See\\nAppendix B for the details of the algorithm.\\n4\\nExperiments\\nWe experimentally evaluate three strategy selection\\nmethods we introduce: OPTS(TS), OPTS(US), and\\nOPTS(APET). Combined with EvoPrompt, these\\nmethods are applied to various tasks and compared\\nwith the existing baseline methods.\\n4.1\\nDataset\\nWe evaluate the proposed method using BIG-Bench\\nHard (BBH; Suzgun et al., 2022). BBH is a col-\\nlection of the tasks that are challenging for LLMs.\\nDetails of each task can be found in the original\\nBBH paper. For each task, we randomly sample\\n50 examples from the test set and use them as the\\ndevelopment set, as done in (Guo et al., 2024). The\\n4\\n\\nPrompt Design Strategy\\nRemarks\\nExpertPrompting\\nAssign expert roles to task-solving LLMs (Xu et al., 2023).\\nChain-of-Thought\\nLet task-solving LLMs also generate a reasoning process (Wei et al., 2022).\\nTree-of-Thought\\nLet task-solving LLMs iteratively choose the best of multiple reasoning paths, back-\\ntracking as necessary (Yao et al., 2023).\\nEmotion Prompting\\nIncorporate phrases that appeal to human emotions (Li et al., 2023).\\nRe-Reading\\nInstruct task-solving LLMs to reread the question (Xu et al., 2024).\\nStyle Prompting\\nSpecifies the desired output style (Lu et al., 2023).\\nRephrase and Respond\\nLet task-solving LLMs rephrase the question before responding (Deng et al., 2024).\\nAvoiding bias\\nA more generalized version of the 13th principle of the 26 principles of prompt-\\ning (Bsharat et al., 2024).\\nMaking prompt specific\\nBased on Best practices for prompt engineering published by OpenAI.1\\nShortening the prompt\\nBased on the experimental result that accuracy can decrease as prompts become\\nlonger (Levy et al., 2024).\\nAdding necessary information\\nOne of the strategies used in APET (Kepel and Valogianni, 2024).\\nTable 1: Prompt design strategies used in the experiment. The concrete descriptions of each strategy are provided in\\nAppendix C.\\ndevelopment set is used for evaluating prompts in\\nthe optimization process. At the end of the opti-\\nmization, the prompt with the highest score on the\\ndevelopment set is tested on the test set excluding\\nthe development set.\\n4.2\\nMetrics\\nWe use accuracy as the scoring function. When\\nevaluating a prompt using task-solving LLMs, an-\\nswer parts are first extracted from the responses\\ngenerated by the LLMs. The regular expression\\nused in lm-evalation-harness (Gao et al., 2024) is\\nused to extract the answer parts. In the regular ex-\\npression, the parts following “the answer is ” are\\nextracted. Then, the scoring function gives a value\\nof 1 if they exactly match the desired responses and\\n0 otherwise.\\n4.3\\nImplementation Details\\nWe evaluate the strategy selection methods with\\nDE-based EvoPrompt. We also evaluate GA-based\\nalgorithm, which is presented in Appendix D. We\\nuse the 3-shot prompts from the original BBH pa-\\nper (Suzgun et al., 2022), but we optimize only the\\ntask description and leave the examples unchanged.\\nWe conduct two experiments in which Llama-3-8B-\\nInstruct (Grattafiori et al., 2024) and GPT-4o mini\\nare used as the task-solving LLMs. In the exper-\\niments using Llama-3-8B-Instruct, we use all 27\\ntasks of the BBH. In the experiments using GPT-4o\\nmini, due to the high API cost, we sample only 3\\n1https://help.openai.com/en/articles/665400\\n0-best-practices-for-prompt-engineering-with-t\\nhe-openai-api. Accessed: Jan. 31, 2025.\\nout of the 27 tasks. We run three trials with dif-\\nferent random seeds in both our experiments with\\nLlama-3-8B-Instruct and GPT-4o mini. We use\\nGPT-4o mini for the prompt-designing LLMs, set\\nthe population size to 10, and perform optimization\\nfor 50 iterations. The prompt design strategies we\\nuse are listed in Table 1.\\n4.4\\nInitial Task Descriptions\\nThe initial task descriptions given at the beginning\\nof the optimization are prepared by the following\\nprocedure. First, we select five task descriptions\\nfrom the 20 prepared descriptions based on their\\nevaluation scores on the development set. The 20\\ntask descriptions consist of those used in the origi-\\nnal BBH paper (Suzgun et al., 2022) and their 19\\nparaphrases generated by GPT-4o mini. For para-\\nphrasing, we use the instruction “Generate 19 vari-\\nations of the following instruction while keeping\\nthe semantic meaning,” which is a slightly modi-\\nfied version of the meta-prompt created by Zhou\\net al. (2023). Then, we use the 10 task descriptions,\\nconsisting of the five selected task descriptions and\\ntheir respective paraphrases by GPT-4o mini, as the\\ninitial task descriptions. When paraphrasing the\\nselected descriptions, in the same way as Guo et al.\\n(2024), we use the meta-prompt for resampling\\nwith the instruction “Generate a variation of the\\nfollowing instruction while keeping the semantic\\nmeaning,” which is created by Zhou et al. (2023).\\n4.5\\nBaseline methods\\nWe use the manual prompts that use those intro-\\nduced in the BBH paper, APET, and EvoPrompt as\\n5\\n\\nTask\\nID\\nTask Name\\nManual\\nPrompt\\nAPET\\nEvoPrompt(DE) EvoPrompt(DE)-\\nOPTS(APET)\\nEvoPrompt(DE)-\\nOPTS(US)\\nEvoPrompt(DE)-\\nOPTS(TS)\\n0\\nboolean expressions\\n54.00\\n67.50\\n74.50 (1.08)\\n79.83 (2.05)\\n84.00 (0.41)\\n82.50 (4.95)\\n1\\ncausal judgement\\n2.19\\n0.00\\n40.39 (3.00)\\n42.34 (2.98)\\n40.15 (4.88)\\n45.50 (3.00)\\n2\\ndate understanding\\n14.00\\n3.00\\n17.17 (1.03)\\n19.17 (4.29)\\n18.67 (5.57)\\n20.17 (6.28)\\n3\\ndisambiguation qa\\n19.50\\n22.50\\n30.00 (1.87)\\n38.33 (4.11)\\n47.33 (6.54)\\n42.50 (5.31)\\n4\\ndyck languages\\n6.50\\n0.00\\n6.67 (0.85)\\n6.50 (0.71)\\n6.17 (0.85)\\n7.50 (0.00)\\n5\\nformal fallacies\\n29.50\\n0.00\\n40.67 (1.31)\\n44.83 (2.66)\\n42.50 (1.22)\\n43.50 (3.56)\\n6\\ngeometric shapes\\n16.50\\n24.50\\n36.00 (0.41)\\n33.00 (0.41)\\n33.00 (4.32)\\n35.83 (2.62)\\n7\\nhyperbaton\\n53.00\\n3.50\\n54.67 (0.85)\\n70.00 (0.82)\\n59.50 (5.02)\\n60.50 (4.42)\\n8\\nlogical deduction five objects\\n12.00\\n3.50\\n14.67 (1.03)\\n29.00 (6.48)\\n24.67 (7.15)\\n37.17 (13.21)\\n9\\nlogical deduction seven objects\\n5.50\\n3.00\\n5.83 (0.24)\\n10.17 (1.25)\\n13.17 (0.85)\\n13.00 (1.87)\\n10\\nlogical deduction three objects\\n44.00\\n20.50\\n45.83 (3.42)\\n70.17 (5.10)\\n71.83 (2.09)\\n78.83 (5.98)\\n11\\nmovie recommendation\\n40.50\\n0.00\\n49.50 (5.12)\\n49.50 (2.83)\\n48.00 (2.48)\\n54.33 (1.89)\\n12\\nmultistep arithmetic two\\n53.50\\n52.00\\n53.50 (1.78)\\n52.17 (2.46)\\n50.33 (0.85)\\n52.50 (1.47)\\n13\\nnavigate\\n84.50\\n38.50\\n83.17 (0.47)\\n80.17 (2.66)\\n81.67 (3.40)\\n84.67 (1.03)\\n14\\nobject counting\\n87.50\\n27.50\\n85.83 (0.62)\\n85.67 (0.62)\\n85.00 (0.82)\\n85.83 (0.24)\\n15\\npenguins in a table\\n26.04\\n8.33\\n22.57 (3.93)\\n28.47 (7.23)\\n41.67 (5.17)\\n40.97 (7.90)\\n16\\nreasoning about colored objects\\n21.00\\n6.50\\n53.00 (3.54)\\n50.00 (4.64)\\n45.67 (5.27)\\n49.50 (3.27)\\n17\\nruin names\\n18.50\\n65.50\\n27.17 (2.90)\\n68.67 (7.26)\\n64.83 (2.39)\\n67.67 (3.66)\\n18\\nsalient translation error detection\\n12.50\\n6.50\\n46.17 (3.52)\\n46.50 (4.71)\\n51.17 (1.55)\\n51.17 (3.66)\\n19\\nsnarks\\n24.22\\n0.00\\n55.47 (6.72)\\n58.59 (3.31)\\n65.10 (4.25)\\n64.06 (1.10)\\n20\\nsports understanding\\n51.52\\n0.00\\n61.45 (1.67)\\n61.62 (1.43)\\n76.94 (7.76)\\n78.45 (4.54)\\n21\\ntemporal sequences\\n57.00\\n6.00\\n65.83 (3.06)\\n65.83 (1.18)\\n60.33 (0.62)\\n66.00 (1.47)\\n22\\ntracking shuffled objects five objects\\n67.50\\n18.00\\n66.50 (2.16)\\n66.17 (0.94)\\n68.17 (1.25)\\n69.33 (1.25)\\n23\\ntracking shuffled objects seven objects\\n47.50\\n19.50\\n52.00 (1.22)\\n52.50 (1.87)\\n54.33 (1.65)\\n49.50 (0.71)\\n24\\ntracking shuffled objects three objects\\n80.50\\n80.50\\n78.67 (1.55)\\n77.50 (2.83)\\n79.17 (1.65)\\n81.67 (2.01)\\n25\\nweb of lies\\n93.50\\n42.00\\n95.00 (0.00)\\n95.00 (0.00)\\n95.00 (0.00)\\n95.00 (0.00)\\n26\\nword sorting\\n44.50\\n41.00\\n45.50 (0.71)\\n45.83 (4.11)\\n46.17 (1.70)\\n45.33 (2.25)\\nAVG\\n39.52\\n20.73\\n48.43\\n52.87\\n53.87\\n55.67\\nTable 2: Accuracy on the test set for 27 tasks from BBH, evaluated with Llama-3-8B-Instruct as the task-solving\\nLLM. The scores are averaged over three trials with different seeds. The values in parentheses represent the standard\\ndeviation. The bold scores indicate that the prompt optimized by the method achieved the highest average score.\\nTask ID\\nEvoPrompt(DE)\\nEvoPrompt(DE)-\\nOPTS(TS)\\n8\\n2.67 (1.43)\\n52.33 (11.45)\\n19\\n79.17 (0.37)\\n79.43 (1.33)\\n23\\n80.67 (4.37)\\n81.83 (3.47)\\nTable 3: Accuracy on the test set for three tasks from\\nBBH, evaluated with GPT-4o mini. The task IDs are the\\nsame as in Table 2. The scores in this table are the aver-\\nage scores over three trials. The values in parentheses\\nrepresent the standard deviation.\\nthe baseline methods. In APET, we use the APET\\nprocedure to incorporate prompt design strategies\\ninto task description in manual prompts.\\n4.6\\nMain Result\\nTable 2 shows the test scores using Llama-3-8B-\\nInstruct as the task-solving LLM.\\nEffects of OPTS.\\nFirst, we focus on the effect\\nof the explicit selection mechanism in OPTS. Ta-\\nble 2 shows that all three variants of OPTS increase\\nthe average scores of EvoPrompt(DE) by approxi-\\nmately 4.5% to 7.5% compared with the naive Evo-\\nPrompt(DE). In particular, for the task “ruin names”\\n(task ID 17), all three variants of EvoPrompt(DE)-\\nOPTS outperform EvoPrompt(DE) by about 40%.\\nThe results indicate that OPTS can improve the\\nprompt optimizer.\\nComparing OPTS Variants.\\nWe compare three\\nselection methods: OPTS(TS), OPTS(US), and\\nOPTS(APET). Table 2 shows that, with Evo-\\nPrompt(DE), OPTS(TS) outperforms OPTS(US)\\nby about 1.7% and OPTS(APET) by about 2.7%\\non average. This result indicates that OPTS(TS)\\ncan select more suitable strategies for task-solving\\nLLMs and tasks. In addition, OPTS(APET) is in-\\nferior to OPTS(US), implying that LLMs have an\\nincorrect bias in selecting prompt design strategies.\\nDifferences between Tasks.\\nTable 2 also shows\\nthat the improvement achieved by strategy selec-\\ntion methods varies depending on the task. For\\nexample, in the tasks of “ruin names” (task ID\\n17) and “logical deduction three objects” (task ID\\n6\\n\\nMethod\\nDescription\\nScore\\nManual Prompt\\nSelect the humorous edit that ’ruins’ the input movie or musical artist\\nname.\\n18.50\\nEvoPrompt(DE)\\nDecide on the eccentric twist that ’spoils’ the name of the movie or music\\nartist.\\n31.00\\nAPET\\n(1) Imagine you are a creative expert in humor and wordplay, skilled at\\ncrafting amusing edits that playfully distort movie or musical artist\\nnames. Your task is to select the humorous edit that ’ruins’ the given\\ninput name in a funny and clever way.\\n(2) Let’s think step-by-step: First, (3) identify the original name provided.\\n(2) Next, (3) brainstorm potential humorous edits that could transform\\nthe name into something amusing while maintaining a connection to\\nthe original. (2) Finally, choose the edit that best exemplifies the concept\\nof ’ruining’ the name in a (4) lighthearted manner.\\n(5) Read the question again to ensure clarity before proceeding. (6) Re-\\nmember, your goal is to evoke laughter and joy through your selection!\\n65.50\\nEvoPrompt(DE)-\\nOPTS(TS)\\n(2) Let’s think step-by-step! First, carefully (5) read the question again\\nand (3) identify a movie title or musician whose name lends itself to\\na humorous spoof. (2) Next, (3) creatively reimagine that title or name\\nwith an absurdly funny twist that maintains the essence of the original\\nwhile injecting a comedic element.\\n(2) Finally, present your funniest\\nversion clearly, ensuring it is both memorable and entertaining.\\n(6) Let\\nyour creativity shine through in this process!\\n70.50\\nTable 4: Examples of the discovered descriptions (optimized parts within the prompts). These achieved the highest\\nscore in each method with Llama-3-8B-Instruct as the task-solving LLM and \"ruin names\" as the task. Underlined\\ntexts represent (1) ExpertPrompting, (2) Chain-of-Thought, (3) Making prompt specific, (4) Style Prompting, (5)\\nRe-Reading, and (6) Emotion Prompting.\\n10), EvoPrompt(DE)-OPTS(TS) outperforms Evo-\\nPrompt(DE) by approximately 40% and 30%, re-\\nspectively. On the other hand, OPTS degrades the\\nperformance of EvoPrompt(DE) in several tasks.\\nA possible reason is that effective prompt design\\nstrategies differ for each task. In tasks with signifi-\\ncant improvement, the eleven candidate strategies\\nused in the experiment likely include effective op-\\ntions. In contrast, it may be difficult for tasks with\\nperformance degradation to achieve better perfor-\\nmance using only the strategies available among the\\neleven candidates. Owing to the inaction arm, we\\nnote that the performance degradation is insignif-\\nicant compared with the degree of performance\\nimprovement.\\n4.7\\nResults Using Another Task-Solving LLM\\nWe also evaluated EvoPrompt(DE)-OPTS(TS) us-\\ning another task-solving LLM, GPT-4o mini, which\\nis one of the most widely used LLMs. We con-\\nducted experiments on three randomly chosen tasks\\nfrom BBH. The experimental setup was the same\\nas the experiment using Llama-3-8B-Instruct. Ta-\\nble 3 shows the accuracy of the test set. We ob-\\nserve that EvoPrompt(DE)-OPTS(TS) outperforms\\nEvoPrompt(DE) in all three tasks. In particular,\\nfor “logical deduction five objects” (task ID 8),\\nOPTS(TS) increases the accuracy by approximately\\n50%. This result suggests that OPTS is likely to be\\neffective regardless of the task-solving LLM.\\n5\\nAnalysis\\nIn this section, we analyze OPTS(TS) from two\\nperspectives: the analyses of the discovered task\\ndescriptions and the case where a strategy was ap-\\nplied more than once.\\nAnalysis of Discovered Descriptions.\\nTable 4\\nshows the discovered task descriptions when us-\\ning Llama-3-8B-Instruct as the task-solving LLMs\\n7\\n\\nBefore or After\\nOPTS\\nDescription\\nBefore\\nLet’s think step-by-step. Identify a humorous variation that spoofs the title of a film\\nor music artist, inventing a funny alteration while preserving its original essence.\\nBefore providing your answer, ensure full clarity and understanding.\\nAfter\\nLet’s think step-by-step. First, identify a film or music artist whose title can be\\nhumorously spoofed. Next, brainstorm a funny alteration that captures the essence\\nof the original title while adding a comedic twist. Finally, clearly articulate your\\nhumorous variation, ensuring that it maintains the original’s core meaning.\\nTable 5: Example of a prompt where Chain-of-Thought prompting is already used, and Chain-of-Thought prompting\\nis selected again and modified accordingly. The task, task-solving LLM, and seed settings are the same as in Table 4.\\nand “ruin names” as the task to be solved. We\\ncan see that the task description discovered by\\nEvoPrompt(DE) does not use any prompt design\\nstrategies and has a structure similar to that of a\\nmanual prompt, which is used to obtain the ini-\\ntial prompts for EvoPrompt. We consider that,\\nalthough the crossover and mutation performed\\nby the prompt-designing LLM in EvoPrompt can\\nchange the phrases in the prompt, it is difficult to\\nchange the structure significantly. In addition, un-\\nlike EvoPrompt(DE), EvoPrompt(DE)-OPTS(TS)\\ndiscovered the task description with various prompt\\ndesign strategies, including CoT, Re-Reading, Mak-\\ning prompt specific, and Emotion Prompting. This\\nresult means that OPTS(TS) significantly improves\\nthe task description using prompt design strategies.\\nWhen comparing EvoPrompt(DE)-OPTS(TS) with\\nAPET, APET incorporated more strategies while its\\nscore was lower than EvoPrompt(DE)-OPTS(TS).\\nImplicit selection by APET has the advantage of\\nselecting and incorporating multiple prompt design\\nstrategies at once, but it may also include unnec-\\nessary strategies. Furthermore, we observe that\\nthe task description of EvoPrompt(DE)-OPTS(TS)\\nuses several prompt design strategies in combina-\\ntion, although OPTS(TS) selects only one prompt\\ndesign strategy at a time. Indeed, Re-Reading and\\nMaking prompt specific are used within the CoT.\\nThis shows that EvoPrompt(DE)-OPTS(TS) pos-\\nsesses the ability to combine multiple prompt de-\\nsign strategies as well as APET.\\nAnalysis of Repeated Selection of a Strategy.\\nDuring the optimization process of EvoPrompt-\\nOPTS(TS), we observed that OPTS(TS) sampled a\\nprompt design strategy that had already been incor-\\nporated into the prompt, thereby further modifying\\nit. Table 5 illustrates a case in which CoT was\\napplied again to a prompt within the same trial as\\nTable 4. The example shows that reapplying CoT\\nfurther aligned the prompt with the strategy. Also,\\nthe feature introduced in the step can be observed\\nin the best prompt in Table 4. This example sug-\\ngests that repeatedly applying the same strategy\\nhelps incorporate it more effectively.\\n6\\nConclusion and Discussion\\nWe introduced explicit selection mechanisms into\\nprompt optimization to effectively leverage existing\\nknowledge of prompt design. Experiments have\\ndemonstrated that the three methods we introduced\\nimprove the performance of the prompt optimizers.\\nIn particular, the method based on Thompson sam-\\npling is the best among those we compared. The\\nprompts discovered by our methods effectively in-\\ncorporate several prompt design strategies, which\\nEvoPrompt alone was unable to discover. Our re-\\nsults highlight the importance of leveraging exist-\\ning knowledge and selecting it explicitly.\\nLimitations\\nThere are four limitations that remain for future\\nresearch: (1) We formulated OPTS(TS) as the\\nBernoulli bandit, but alternative reward formula-\\ntion may improve optimization performance. (2)\\nAlthough OPTS can be easily integrated into vari-\\nous prompt optimizers, we have not attempted to in-\\ntroduce it to other optimizers than EvoPrompt. (3)\\nWe used Thompson sampling to select the prompt\\ndesign strategy but did not evaluate other sophis-\\nticated methods, such as contextual bandit algo-\\nrithms. (4) The performance of OPTS mechanism\\ncan vary depending on the prompt design strat-\\negy prepared, but this is not clarified in this paper.\\nThese points remain topics for future research.\\n8\\n\\nEthical Considerations\\nOur method may involve the risk of being used to\\noptimize prompts that generate malicious content,\\nsuch as malware or fake news, even though this is\\nnot the intention of our method. At present, it is\\nextremely difficult to reduce this risk. Although our\\nmethod may be beneficial to some malicious users,\\nwe expect that our method can be more beneficial\\nto many other benevolent users.\\nReferences\\nEshaan Agarwal, Joykirat Singh, Vivek Dani, Raghav\\nMagazine, Tanuja Ganu, and Akshay Nambi. 2024.\\nPromptWizard:\\nTask-aware prompt optimization\\nframework. Preprint, arXiv:2405.18369.\\nSondos Mahmoud Bsharat, Aidar Myrzakhan, and\\nZhiqiang Shen. 2024. Principled instructions are\\nall you need for questioning LLaMA-1/2, GPT-3.5/4.\\nPreprint, arXiv:2312.16171.\\nKaiyan Chang, Songcheng Xu, Chenglong Wang,\\nYingfeng Luo, Xiaoqian Liu, Tong Xiao, and\\nJingbo Zhu. 2024.\\nEfficient prompting methods\\nfor large language models: A survey.\\nPreprint,\\narXiv:2404.01077.\\nOlivier Chapelle and Lihong Li. 2011. An empirical\\nevaluation of Thompson sampling. In Advances in\\nNeural Information Processing Systems, volume 24.\\nCurran Associates, Inc.\\nWendi Cui, Jiaxin Zhang, Zhuohang Li, Hao Sun,\\nDamien Lopez, Kamalika Das, Bradley A. Malin,\\nand Sricharan Kumar. 2024. PhaseEvo: Towards uni-\\nfied long-context prompt optimization for large lan-\\nguage models. In First Workshop on Long-Context\\nFoundation Models @ ICML 2024.\\nYihe Deng, Weitong Zhang, Zixiang Chen, and Quan-\\nquan Gu. 2024. Rephrase and respond: Let large\\nlanguage models ask better questions for themselves.\\nPreprint, arXiv:2311.04205.\\nChrisantha\\nFernando,\\nDylan\\nBanarse,\\nHenryk\\nMichalewski, Simon Osindero, and Tim Rock-\\ntäschel. 2023.\\nPromptbreeder:\\nSelf-referential\\nself-improvement via prompt evolution. Preprint,\\narXiv:2309.16797.\\nLeo Gao, Jonathan Tow, Baber Abbasi, Stella Bider-\\nman, Sid Black, Anthony DiPofi, Charles Foster,\\nLaurence Golding, Jeffrey Hsu, Alain Le Noac’h,\\nHaonan Li, Kyle McDonell, Niklas Muennighoff,\\nChris Ociepa, Jason Phang, Laria Reynolds, Hailey\\nSchoelkopf, Aviya Skowron, Lintang Sutawika, and\\n5 others. 2024. A framework for few-shot language\\nmodel evaluation.\\nAaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri,\\nAbhinav Pandey, Abhishek Kadian, Ahmad Al-\\nDahle, Aiesha Letman, Akhil Mathur, Alan Schel-\\nten, Alex Vaughan, Amy Yang, Angela Fan, Anirudh\\nGoyal, Anthony Hartshorn, Aobo Yang, Archi Mi-\\ntra, Archie Sravankumar, Artem Korenev, Arthur\\nHinsvark, and 542 others. 2024. The Llama 3 herd\\nof models. Preprint, arXiv:2407.21783.\\nQingyan Guo, Rui Wang, Junliang Guo, Bei Li, Kaitao\\nSong, Xu Tan, Guoqing Liu, Jiang Bian, and Yujiu\\nYang. 2024. Connecting large language models with\\nevolutionary algorithms yields powerful prompt opti-\\nmizers. In The Twelfth International Conference on\\nLearning Representations.\\nBeichen Huang, Xingyu Wu, Yu Zhou, Jibin Wu, Liang\\nFeng, Ran Cheng, and Kay Chen Tan. 2024. Ex-\\nploring the true potential: Evaluating the black-box\\noptimization capability of large language models.\\nPreprint, arXiv:2404.06290.\\nFeihu Jin, Yifan Liu, and Ying Tan. 2024.\\nZero-\\nshot chain-of-thought reasoning guided by evolution-\\nary algorithms in large language models. Preprint,\\narXiv:2402.05376.\\nDaniel Martin Katz, Michael James Bommarito, Shang\\nGao, and Pablo Arredondo. 2024. GPT-4 passes the\\nbar exam. Philosophical Transactions of the Royal\\nSociety A: Mathematical, Physical and Engineering\\nSciences, 382(2270):20230254.\\nDaan Kepel and Konstantina Valogianni. 2024. Au-\\ntonomous prompt engineering in large language mod-\\nels. Preprint, arXiv:2407.11000.\\nTakeshi Kojima, Shixiang (Shane) Gu, Machel Reid, Yu-\\ntaka Matsuo, and Yusuke Iwasawa. 2022. Large lan-\\nguage models are zero-shot reasoners. In Advances in\\nNeural Information Processing Systems, volume 35,\\npages 22199–22213. Curran Associates, Inc.\\nMosh Levy, Alon Jacoby, and Yoav Goldberg. 2024.\\nSame task, more tokens: the impact of input length\\non the reasoning performance of large language mod-\\nels. In Proceedings of the 62nd Annual Meeting of\\nthe Association for Computational Linguistics (Vol-\\nume 1: Long Papers), pages 15339–15353, Bangkok,\\nThailand. Association for Computational Linguistics.\\nCheng Li, Jindong Wang, Yixuan Zhang, Kaijie Zhu,\\nWenxin Hou, Jianxun Lian, Fang Luo, Qiang Yang,\\nand Xing Xie. 2023. Large language models un-\\nderstand and can be enhanced by emotional stimuli.\\nPreprint, arXiv:2307.11760.\\nDo Long, Yiran Zhao, Hannah Brown, Yuxi Xie, James\\nZhao, Nancy Chen, Kenji Kawaguchi, Michael Shieh,\\nand Junxian He. 2024. Prompt optimization via ad-\\nversarial in-context learning. In Proceedings of the\\n62nd Annual Meeting of the Association for Com-\\nputational Linguistics (Volume 1: Long Papers),\\npages 7308–7327, Bangkok, Thailand. Association\\nfor Computational Linguistics.\\n9\\n\\nAlbert Lu, Hongxin Zhang, Yanzhe Zhang, Xuezhi\\nWang, and Diyi Yang. 2023. Bounding the capabili-\\nties of large language models in open text generation\\nwith prompt constraints. In Findings of the Asso-\\nciation for Computational Linguistics: EACL 2023,\\npages 1982–2008, Dubrovnik, Croatia. Association\\nfor Computational Linguistics.\\nHarsha Nori, Nicholas King, Scott Mayer McKinney,\\nDean Carignan, and Eric Horvitz. 2023. Capabilities\\nof GPT-4 on medical challenge problems. Preprint,\\narXiv:2303.13375.\\nOpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal,\\nLama Ahmad, Ilge Akkaya, Florencia Leoni Ale-\\nman, Diogo Almeida, Janko Altenschmidt, Sam Alt-\\nman, Shyamal Anadkat, Red Avila, Igor Babuschkin,\\nSuchir Balaji, Valerie Balcom, Paul Baltescu, Haim-\\ning Bao, Mohammad Bavarian, Jeff Belgum, and\\n262 others. 2024. GPT-4 technical report. Preprint,\\narXiv:2303.08774.\\nArchiki Prasad, Peter Hase, Xiang Zhou, and Mohit\\nBansal. 2023. GRIPS: Gradient-free, edit-based in-\\nstruction search for prompting large language models.\\nIn Proceedings of the 17th Conference of the Euro-\\npean Chapter of the Association for Computational\\nLinguistics, pages 3845–3864, Dubrovnik, Croatia.\\nAssociation for Computational Linguistics.\\nReid Pryzant, Dan Iter, Jerry Li, Yin Lee, Chenguang\\nZhu, and Michael Zeng. 2023. Automatic prompt op-\\ntimization with “gradient descent” and beam search.\\nIn Proceedings of the 2023 Conference on Empiri-\\ncal Methods in Natural Language Processing, pages\\n7957–7968, Singapore. Association for Computa-\\ntional Linguistics.\\nBaptiste Rozière, Jonas Gehring, Fabian Gloeckle, Sten\\nSootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi,\\nJingyu Liu, Romain Sauvestre, Tal Remez, Jérémy\\nRapin, Artyom Kozhevnikov, Ivan Evtimov, Joanna\\nBitton, Manish Bhatt, Cristian Canton Ferrer, Aaron\\nGrattafiori, Wenhan Xiong, Alexandre Défossez, and\\n7 others. 2024. Code Llama: Open foundation mod-\\nels for code. Preprint, arXiv:2308.12950.\\nDaniel J Russo, Benjamin Van Roy, Abbas Kazerouni,\\nIan Osband, Zheng Wen, and 1 others. 2018.\\nA\\ntutorial on thompson sampling. Foundations and\\nTrends® in Machine Learning, 11(1):1–96.\\nSander Schulhoff, Michael Ilie, Nishant Balepur, Kon-\\nstantine Kahadze, Amanda Liu, Chenglei Si, Yin-\\nheng Li, Aayush Gupta, HyoJung Han, Sevien Schul-\\nhoff, Pranav Sandeep Dulepet, Saurav Vidyadhara,\\nDayeon Ki, Sweta Agrawal, Chau Pham, Gerson\\nKroiz, Feileen Li, Hudson Tao, Ashay Srivastava,\\nand 12 others. 2024.\\nThe prompt report: A sys-\\ntematic survey of prompting techniques. Preprint,\\narXiv:2406.06608.\\nMirac Suzgun, Nathan Scales, Nathanael Schärli, Se-\\nbastian Gehrmann, Yi Tay, Hyung Won Chung,\\nAakanksha Chowdhery, Quoc V. Le, Ed H. Chi,\\nDenny Zhou, and Jason Wei. 2022.\\nChallenging\\nbig-bench tasks and whether chain-of-thought can\\nsolve them. Preprint, arXiv:2210.09261.\\nGemini Team, Rohan Anil, Sebastian Borgeaud, Jean-\\nBaptiste Alayrac, Jiahui Yu, Radu Soricut, Johan\\nSchalkwyk, Andrew M. Dai, Anja Hauth, Katie\\nMillican, David Silver, Melvin Johnson, Ioannis\\nAntonoglou, Julian Schrittwieser, Amelia Glaese,\\nJilin Chen, Emily Pitler, Timothy Lillicrap, Angeliki\\nLazaridou, and 1331 others. 2024. Gemini: A fam-\\nily of highly capable multimodal models. Preprint,\\narXiv:2312.11805.\\nWilliam R Thompson. 1933. On the likelihood that one\\nunknown probability exceeds another in view of the\\nevidence of two samples. Biometrika, 25(3-4):285–\\n294.\\nNoah Wang, Z.y. Peng, Haoran Que, Jiaheng Liu,\\nWangchunshu Zhou, Yuhan Wu, Hongcheng Guo,\\nRuitong Gan, Zehao Ni, Jian Yang, Man Zhang,\\nZhaoxiang Zhang, Wanli Ouyang, Ke Xu, Wenhao\\nHuang, Jie Fu, and Junran Peng. 2024a. RoleLLM:\\nBenchmarking, eliciting, and enhancing role-playing\\nabilities of large language models. In Findings of\\nthe Association for Computational Linguistics: ACL\\n2024, pages 14743–14777, Bangkok, Thailand. As-\\nsociation for Computational Linguistics.\\nXinyuan Wang, Chenxi Li, Zhen Wang, Fan Bai, Hao-\\ntian Luo, Jiayou Zhang, Nebojsa Jojic, Eric Xing, and\\nZhiting Hu. 2024b. PromptAgent: Strategic planning\\nwith language models enables expert-level prompt op-\\ntimization. In The Twelfth International Conference\\non Learning Representations.\\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\\nBosma, brian ichter, Fei Xia, Ed Chi, Quoc V Le,\\nand Denny Zhou. 2022. Chain-of-thought prompt-\\ning elicits reasoning in large language models. In\\nAdvances in Neural Information Processing Systems,\\nvolume 35, pages 24824–24837. Curran Associates,\\nInc.\\nBenfeng Xu, An Yang, Junyang Lin, Quan Wang,\\nChang Zhou, Yongdong Zhang, and Zhendong Mao.\\n2023.\\nExpertPrompting:\\nInstructing large lan-\\nguage models to be distinguished experts. Preprint,\\narXiv:2305.14688.\\nXiaohan Xu, Chongyang Tao, Tao Shen, Can Xu,\\nHongbo Xu, Guodong Long, Jian-Guang Lou, and\\nShuai Ma. 2024. Re-reading improves reasoning\\nin large language models.\\nIn Proceedings of the\\n2024 Conference on Empirical Methods in Natural\\nLanguage Processing, pages 15549–15575, Miami,\\nFlorida, USA. Association for Computational Lin-\\nguistics.\\nChengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao\\nLiu, Quoc V Le, Denny Zhou, and Xinyun Chen.\\n2024.\\nLarge language models as optimizers.\\nIn\\nThe Twelfth International Conference on Learning\\nRepresentations.\\n10\\n\\nShunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran,\\nTom Griffiths, Yuan Cao, and Karthik Narasimhan.\\n2023. Tree of thoughts: Deliberate problem solving\\nwith large language models. In Advances in Neural\\nInformation Processing Systems, volume 36, pages\\n11809–11822. Curran Associates, Inc.\\nMingqian Zheng, Jiaxin Pei, Lajanugen Logeswaran,\\nMoontae Lee, and David Jurgens. 2024. When ”a\\nhelpful assistant” is not really helpful: Personas in\\nsystem prompts do not improve performances of\\nlarge language models. In Findings of the Associ-\\nation for Computational Linguistics: EMNLP 2024,\\npages 15126–15154, Miami, Florida, USA. Associa-\\ntion for Computational Linguistics.\\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han,\\nKeiran Paster, Silviu Pitis, Harris Chan, and Jimmy\\nBa. 2023. Large language models are human-level\\nprompt engineers.\\nIn The Eleventh International\\nConference on Learning Representations.\\nA\\nMeta-Prompt for OPTS\\nThe meta-prompt we used was based on APET (Ke-\\npel and Valogianni, 2024) as shown in Table 6. We\\nfed this meta-prompt into the prompt-designing\\nLLMs after replacing the <strategy> tag with de-\\nscriptions of the prompt design strategies and the\\n<input> tag with the prompt to be modified. For\\nAPET and OPTS(APET), the <strategy> tag was\\nreplaced with the list of K tags from <strategy\\n1> to <strategy K>, where the description of each\\nprompt design strategy is inserted.\\nB\\nDetails of EvoPrompt-OPTS\\nThe algorithm that integrates OPTS into Evo-\\nPrompt(GA) is shown in Algorithm 2. In the fol-\\nlowing, we provide supplementary explanations\\nregarding EvoPrompt processes.\\nCrossover\\nand\\nMutation.\\nThe\\nprompt-\\ndesigning LLM performs crossover and mutation\\nbased on the meta-prompts and prompts fed into\\nthem. The meta-prompts for EvoPrompt(GA) and\\nEvoPrompt(DE) are described in Tables 7 and 8,\\nrespectively.\\nIn EvoPrompt(GA), two prompts are selected\\nas parents using roulette wheel selection. They\\nare fed into the prompt-designing LLM along\\nwith the meta-prompt by replacing <prompt1> and\\n<prompt2> in the meta-prompt provided in Table 7\\nwith them. The LLM then generates an offspring\\nprompt according to the meta-prompt.\\nIn EvoPrompt(DE), four prompts in the cur-\\nrent population are used to generate an offspring\\nprompt: two randomly selected prompts pr1 and\\npr2, the current best prompt pbest, and a parent\\nprompt. Each prompt in the current population is\\nselected once as the parent prompt. Those four\\nprompts are fed into the prompt-designing LLM\\nby replacing <prompt0>, <prompt1>, <prompt2>,\\nand <prompt3> in Table 8 with the parent prompt,\\npr1, pr2, and pbest, respectively. The LLM then\\nperforms crossover and mutation to generate an\\noffspring prompt according to the meta-prompt.\\nC\\nDescriptions of Prompt Design\\nStrategies\\nTable 9 provides the descriptions for each of the 11\\nprompt design strategies used in our experiment.\\nD\\nGA-Based Experimental Results\\nIn this section, we present the GA-based experi-\\nmental results. Table 10 shows the result of the\\nexperiment using Llama-3-8B-Instruct as a task-\\nsolving LLM, and Table 11 shows the result of the\\nexperiment using GPT-4o mini as a task-solving\\nLLM. Tables 10 and 11 show that, as in the DE-\\nbased experiments, the performance of EvoPrompt\\n(GA) is enhanced by selecting suitable prompt de-\\nsign strategy using OPTS. In addition, when com-\\nparing the variations of OPTS, we observe a ten-\\ndency that OPTS(TS) is overall the best, followed\\nby OPTS(US) and OPTS(APET), as in the case of\\nthe EvoPrompt(DE). In terms of the extent of im-\\nprovement, combining the mechanism for selecting\\na prompt design strategy with EvoPrompt(DE) has\\na greater impact than that with EvoPrompt(GA).\\nThese results suggest that, although the extent of\\nimprovement varies slightly depending on the evo-\\nlutionary algorithm used in the prompt optimizer,\\nthe mechanism to select the prompt design strategy\\ncan enhance the prompt optimizer regardless of the\\nevolutionary algorithm used.\\nE\\nLicense for Artifacts\\nBIG-Bench Hard and lm-evaluation-harness are\\nlicensed under the MIT License.\\nLlama-3-8B-\\nInstruct is licensed under META LLAMA 3 COM-\\nMUNITY LICENSE AGREEMENT. Our code will\\nalso be released under the MIT license.\\nF\\nArtifact Use Consistent with Intended\\nUse\\nWe declare that we have used the BIG-Bench Hard\\ndataset and Llama-3-8B-Instruct in accordance\\nwith their original intended use. Additionally, we\\n11\\n\\nSystem prompt\\nImagine yourself as an expert in the realm of prompting techniques for LLMs. Your expertise is not\\njust broad, encompassing the entire spectrum of current knowledge on the subject, but also deep,\\ndelving into the nuances and intricacies that many overlook. Your job is to reformulate prompts\\nwith surgical precision, optimizing them for the most accurate response possible. The reformulated\\nprompt should enable the LLM to always give the correct answer to the question.\\nUser prompt\\nYour available prompting techniques include, but are not limited to the following:\\n- <strategy>\\nYour approach is methodical and analytical, yet creative. You use a mixture of the prompting\\ntechniques, making sure you pick the right combination for each instruction. You see beyond the\\nsurface of a prompt, identifying the core objectives and the best ways to articulate them to achieve\\nthe desired outcomes.\\nOutput instructions:\"\"\"\"\\nYou should ONLY return the reformulated prompt. Make sure to include ALL information from\\nthe given prompt to reformulate.\\n\"\"\"\"\\nGiven above information and instructions, reformulate below prompt using the techniques\\nprovided: \"\"\"\"\\n<input>\\n\"\"\"\\nTable 6: Meta-prompt for OPTS and APET (Kepel and Valogianni, 2024). When APET or OPTS(APET) is used,\\nK <strategy> tags (i.e., <strategy 1>, <strategy 2>, ..., <strategy K>) are provided, and each of them is\\nreplaced with one prompt design strategy description.\\nprohibit the use of the code we release for optimiz-\\ning prompts to generate malicious content, except\\nfor research purposes.\\nG\\nExperimental Environment\\nOur experiments were conducted on a computer\\nrunning Ubuntu 22.04 with an AMD EPYC 7502P\\nCPU and an NVIDIA A100 GPU, and on another\\ncomputer running Ubuntu 22.04 with an AMD\\nEPYC 7702P CPU and an NVIDIA A100 GPU.\\nWe used openai 1.40.8 as the python library to\\naccess GPT-4o mini, and vllm 0.6.3.post1 as the\\npython library to access llama-3-8B-Instruct.\\n12\\n\\nUser prompt\\nPlease follow the instruction step-by-step to generate a better prompt.\\n1. Crossover the following prompts to generate a new prompt:\\nPrompt 1: Your task is to classify the comment as one of the following categories: terrible, bad,\\nokay, good, great.\\nPrompt 2: In this task, you are given sentences from movie reviews. The task is to classify a\\nsentence as one of the following categories: terrible, bad, okay, good, great.\\n2. Mutate the prompt generated in Step 1 and generate a final prompt bracketed with <prompt> and\\n</prompt>.\\n1.\\nCrossover Prompt: In this task, you are given comments from movie reviews.\\nYour\\ntask is to classify each comment as one of the following categories: terrible, bad, okay, good, great.\\n2. <prompt>Given a sentence from a movie review, classify it into one of the following categories:\\nterrible, bad, okay, good, or great.</prompt>\\nPlease follow the instruction step-by-step to generate a better prompt.\\n1. Crossover the following prompts and generate a new prompt:\\nPrompt 1: <prompt1>\\nPrompt 2: <prompt2>\\n2. Mutate the prompt generated in Step 1 and generate a final prompt bracketed with <prompt> and\\n</prompt>.\\n1.\\nTable 7: Meta-prompt for crossover and mutation in EvoPrompt(GA) (Guo et al., 2024).\\nAlgorithm 2 EvoPrompt(GA)-OPTS\\nRequire: Initial prompts P0 = {p1, p2, . . . , pN}, population size N, number of iterations T, development\\nset Ddev consisting of input and correct output pairs (x, y), scoring function g, task-solving LLM fT\\n1: Evaluation of initial prompts: S0 ←\\nn\\nsi =\\n1\\n|Ddev|\\nP\\n(x,y)∈Ddev g (y, fT (pi, x)) : pi ∈P0\\no\\n2: for t = 1 to T do\\n3:\\nfor i = 1 to N do\\n4:\\nSampling parents by roulette wheel: pr1, pr2 ∈Pt−1\\n5:\\nCrossover and Mutation: p′\\ni ←fD(mga, (pr1, pr2))\\n6:\\n▷fD: prompt-designing LLM\\n7:\\n▷mga: Meta-prompt for GA-based crossover and mutation\\n8:\\nOPTS: Generate p′′\\ni from p′\\ni by incorporating prompt design strategies (Refer to Section 3.1)\\n9:\\nEvaluation: s′′\\ni ←\\n1\\n|Ddev|\\nP\\n(x,y)∈Ddev g (y, fT (p′′\\ni , x))\\n10:\\nUpdate probability distribution if the TS-based selection is used (Refer to Section 3.1)\\n11:\\nend for\\n12:\\nˆSt ←{s′′\\ni : 1 ≤i ≤N}, ˆPt ←{p′′\\ni : 1 ≤i ≤N}\\n13:\\nUpdate score: St ←select the best N scores in St−1 ∪ˆSt\\n14:\\nUpdate: Pt ←select the best N prompts in Pt−1 ∪ˆPt according to St−1 ∪ˆSt,\\n15: end for\\n16: Return the best prompt p∗= argmaxp∈PT\\n1\\n|Ddev|\\nP\\n(x,y)∈Ddev g (y, fT (p, x))\\n13\\n\\nUser prompt\\nPlease follow the instruction step-by-step to generate a better prompt.\\n1. Identify the different parts between the Prompt 1 and Prompt 2:\\nPrompt 1: Rewrite the input text into simpler text.\\nPrompt 2: Rewrite my complex sentence in simpler terms, but keep the meaning.\\n2. Randomly mutate the different parts\\n3. Combine the different parts with Prompt 3, selectively replace it with the different parts in step 2\\nand generate a new prompt.\\nPrompt 3: Rewrite the given input text into simpler English sentences while preserving the same\\nmeaning, so it can be understood by non-native English speakers.\\n4. Crossover the prompt in the step3 with the following basic prompt and generate a final prompt\\nbracketed with <prompt> and </prompt>:\\nBasic Prompt: Make the sentence easier for people who do not speak English fluently to\\ncomprehend.\\n1. Identifying the different parts between Prompt 1 and Prompt 2:\\nPrompt 1: Rewrite the input text into simpler text.\\nPrompt 2: Rewrite my complex sentence in simpler terms, but keep the meaning.\\nDifferent parts:\\n\"input text\" vs \"my complex sentence\"\\n\"simpler text\" vs \"simpler terms, but keep the meaning\"\\n2. Randomly mutate the different parts:\\n\"input text\" -> \"provided text\"\\n\"my complex sentence\" -> \"the difficult sentence\"\\n\"simpler text\" -> \"easier language\"\\n\"simpler terms, but keep the meaning\" -> \"simpler words while maintaining the meaning\"\\n3.\\nCombine the different parts with Prompt 3, selectively replace it with the different\\nparts in step 2 and generate a new prompt:\\nPrompt 3: Rewrite the given input text into simpler English sentences while preserving the same\\nmeaning, so it can be understood by non-native English speakers.\\nNew Prompt: Transform the provided text into easier language while maintaining the meaning,\\nmaking it accessible for non-native English speakers.\\n4.\\nCrossover the prompt in step 3 with the following basic prompt and generate a final\\nprompt bracketed with <prompt> and </prompt>:\\nBasic Prompt: Make the sentence easier for people who do not speak English fluently to\\ncomprehend.\\nFinal Prompt: <prompt>Convert the difficult sentence into simpler words while preserving the\\nmeaning, so it’s easier for non-native English speakers to understand.</prompt>\\nPlease follow the instruction step-by-step to generate a better prompt.\\n1. Identify the different parts between the Prompt 1 and Prompt 2:\\nPrompt 1: <prompt1>\\nPrompt 2: <prompt2>\\n2. Randomly mutate the different parts\\n3. Combine the different parts with Prompt 3, selectively replace it with the different parts in step2\\nand generate a new prompt.\\nPrompt 3: <prompt3>\\n4. Crossover the prompt in the step3 with the following basic prompt and generate a final prompt\\nbracketed with <prompt> and </prompt>:\\nBasic Prompt: <prompt0>\\n1. \"\"\"\\nTable 8: Meta-prompt for crossover and mutation in EvoPrompt(DE) (Guo et al., 2024).\\n14\\n\\nExpertPrompting\\nCrafting an expert who is an expert at the given task, by writing a high-quality\\ndescription about the most capable and suitable agent to answer the instruction in\\nsecond person perspective.\\nChain-of-Thought\\nExplaining step-by-step how the problem should be tackled, and making sure the\\nmodel explains step-by-step how it came to the answer. You can do this by adding\\n\"Let’s think step-by-step\".\\nTree-of-Thought\\nImagining three different experts who are discussing the problem at hand. All experts\\nwill write down 1 step of their thinking, then share it with the group. Then all experts\\nwill go on to the next step, etc. If any expert realises they’re wrong at any point then\\nthey leave.\\nAdding necessary information\\nMaking sure all information needed is in the prompt, adding where necessary but\\nmaking sure the question remains having the same objective.\\nRe-Reading\\nFor a given prompt, add a phrase such as \"Read the question again\" that instructs the\\nLarge Language Models to reread the question before generating an answer. This\\nstrategy is particularly effective for complex tasks and helps enhance the quality and\\nreliability of the model’s outputs.\\nStyle Prompting\\nClearly define the desired style in the given prompt. For example, you might say,\\n\"Write a formal letter about...\" or \"Create a casual conversation discussing...\". This\\nguidance helps the model produce text that matches the requested stylistic elements,\\nwhether it’s formal, informal, technical, or poetic.\\nRephrase and Respond\\nFor a given prompt, add a phrase that instructs the Large Language Models to rephrase\\nthe question before responding, such as \"Rephrase and expand the question, and\\nrespond.\\nMaking prompt specific\\nMake the description of the given prompt more specific. This makes it easier for Large\\nLanguage Models to correctly execute prompt instructions.\\nAvoiding bias\\nTo allow Large Language Models to make logical and unbiased inferences, add phrases\\nto a given prompt that instruct it to remove opinionated content. This helps the model\\nconcentrate on providing responses based on careful analysis and logical reasoning,\\nminimizing biases.\\nShortening the prompt\\nIf a given prompt has long instructions, make it shorter by condensing it to only the\\nessential parts.\\nEmotion Prompting\\nAt the end of the prompt, add a phrase that evokes a strong emotion. When doing so,\\nkeep the following four points in mind:\\n1. Define emotional goals: Identify the emotional response you want to evoke, such as\\nencouragement, motivation, or reassurance.\\n2. Use positive language: Incorporate words and phrases that are positive and sup-\\nportive. Examples include \"believe in your abilities,\" \"excellent,\" \"success,\" and\\n\"outstanding achievements\".\\n3. Emphasize key words: Use techniques like exclamation marks and capitalized\\nwords to highlight important aspects and to enhance the emotional impact.\\n4. Incorporate social and self-esteem cues: Design stimuli that leverage social influ-\\nence (e.g., group membership, others’ opinions) and boost self-esteem and motivation.\\nThis can help regulate the emotional response of the Large Language Models and tap\\ninto intrinsic motivation.\\nTable 9: Descriptions of each prompt design strategy. Descriptions of ExpertPrompting, Chain-of-Thought, Tree-of-\\nThought, and Adding necessary information are quoted from APET (Kepel and Valogianni, 2024). The descriptions\\nRe-Reading, Style Prompting, Rephrase and Respond, and Emotion Prompting are modified versions of descriptions\\ncreated using GPT-4o from Xu et al. (2024), Lu et al. (2023), Deng et al. (2024), and Li et al. (2023), respectively.\\nDescription of Making prompt specific is created by us and is inspired by OpenAI’s prompt engineering best practice.\\nDescription of Avoiding bias is created by us by referring to and generalizing the 13th principle of the 26 prompting\\nprinciples proposed in Bsharat et al. (2024). Description of Shortening the prompt was created by us.\\n15\\n\\nTask\\nID\\nTask name\\nManual\\nprompt\\nAPET\\nEvoPrompt(GA) EvoPrompt(GA)-\\nOPTS(APET)\\nEvoPrompt(GA)-\\nOPTS(US)\\nEvoPrompt(GA)-\\nOPTS(TS)\\n0\\nboolean expressions\\n54.00\\n67.50\\n72.83 (3.30)\\n84.33 (3.66)\\n83.00 (2.94)\\n85.67 (1.65)\\n1\\ncausal judgement\\n2.19\\n0.00\\n37.71 (1.82)\\n40.88 (2.60)\\n44.53 (3.10)\\n44.53 (0.60)\\n2\\ndate understanding\\n14.00\\n3.00\\n13.67 (0.85)\\n14.50 (5.10)\\n21.17 (10.38)\\n16.00 (0.82)\\n3\\ndisambiguation qa\\n19.50\\n22.50\\n32.17 (4.33)\\n37.00 (2.86)\\n42.67 (3.27)\\n49.67 (6.91)\\n4\\ndyck languages\\n6.50\\n0.00\\n6.67 (0.94)\\n6.50 (0.71)\\n5.83 (0.24)\\n6.50 (0.00)\\n5\\nformal fallacies\\n29.50\\n0.00\\n42.50 (0.71)\\n45.17 (2.05)\\n43.83 (0.85)\\n44.50 (0.82)\\n6\\ngeometric shapes\\n16.50\\n24.50\\n29.83 (7.85)\\n37.33 (6.14)\\n33.00 (4.26)\\n32.67 (2.95)\\n7\\nhyperbaton\\n53.00\\n3.50\\n54.83 (0.94)\\n61.67 (1.55)\\n57.67 (3.57)\\n63.67 (6.51)\\n8\\nlogical deduction five objects\\n12.00\\n3.50\\n12.33 (1.31)\\n20.00 (1.22)\\n24.67 (4.03)\\n25.83 (7.96)\\n9\\nlogical deduction seven objects\\n5.50\\n3.00\\n6.83 (3.01)\\n7.83 (3.09)\\n12.17 (1.55)\\n11.33 (1.70)\\n10\\nlogical deduction three objects\\n44.00\\n20.50\\n58.17 (5.72)\\n64.00 (3.89)\\n59.67 (6.02)\\n66.67 (3.30)\\n11\\nmovie recommendation\\n40.50\\n0.00\\n48.67 (1.18)\\n49.67 (4.17)\\n53.50 (4.90)\\n52.50 (1.63)\\n12\\nmultistep arithmetic two\\n53.50\\n52.00\\n50.33 (2.25)\\n49.83 (1.25)\\n46.83 (2.72)\\n50.17 (1.03)\\n13\\nnavigate\\n84.50\\n38.50\\n79.67 (4.25)\\n80.17 (2.32)\\n83.83 (3.01)\\n82.33 (2.25)\\n14\\nobject counting\\n87.50\\n27.50\\n85.50 (0.71)\\n82.67 (3.70)\\n86.67 (0.62)\\n84.33 (0.62)\\n15\\npenguins in a table\\n26.04\\n8.33\\n25.00 (1.47)\\n29.86 (8.26)\\n30.90 (2.99)\\n32.29 (1.47)\\n16\\nreasoning about colored objects\\n21.00\\n6.50\\n50.17 (9.33)\\n47.50 (1.08)\\n47.00 (6.38)\\n52.33 (2.72)\\n17\\nruin names\\n18.50\\n65.50\\n51.00 (13.83)\\n63.17 (3.52)\\n67.33 (0.24)\\n66.83 (0.47)\\n18\\nsalient translation error detection\\n12.50\\n6.50\\n31.67 (9.74)\\n49.00 (4.42)\\n48.17 (4.48)\\n52.67 (1.03)\\n19\\nsnarks\\n24.22\\n0.00\\n45.83 (6.03)\\n52.60 (15.94)\\n64.84 (2.92)\\n60.16 (4.42)\\n20\\nsports understanding\\n51.52\\n0.00\\n62.63 (0.00)\\n62.63 (0.00)\\n65.15 (2.58)\\n61.95 (6.20)\\n21\\ntemporal sequences\\n57.00\\n6.00\\n63.67 (3.70)\\n59.33 (2.49)\\n61.83 (1.43)\\n61.33 (2.78)\\n22\\ntracking shuffled objects five objects\\n67.50\\n18.00\\n67.67 (0.47)\\n67.83 (0.24)\\n68.67 (2.66)\\n67.33 (1.03)\\n23\\ntracking shuffled objects seven objects\\n47.50\\n19.50\\n53.33 (2.49)\\n51.50 (0.82)\\n52.00 (1.08)\\n50.33 (1.84)\\n24\\ntracking shuffled objects three objects\\n80.50\\n80.50\\n81.00 (0.71)\\n81.67 (0.62)\\n80.67 (0.24)\\n82.33 (0.62)\\n25\\nweb of lies\\n93.50\\n42.00\\n96.33 (1.03)\\n95.83 (0.62)\\n96.33 (1.43)\\n96.00 (1.47)\\n26\\nword sorting\\n44.50\\n41.00\\n46.83 (1.65)\\n43.67 (4.40)\\n46.00 (7.08)\\n44.17 (1.03)\\nAVG\\n39.52\\n20.73\\n48.40\\n51.34\\n52.89\\n53.48\\nTable 10: Accuracy on the test set for 27 tasks from BBH, evaluated with Llama-3-8B-Instruct as the task-solving\\nLLM. The scores are averaged over three trials with different seeds. The values in parentheses represent the standard\\ndeviation. The bold scores indicate that the prompt optimized by the method achieved the highest average score.\\nTask ID\\nEvoPrompt(GA)\\nEvoPrompt(GA)-\\nOPTS(TS)\\n8\\n1.67 (0.85)\\n48.17 (5.14)\\n19\\n79.43 (1.33)\\n78.65 (1.84)\\n23\\n75.67 (1.25)\\n88.33 (1.55)\\nTable 11: Accuracy on the test set for three tasks from BBH, evaluated with GPT-4o mini. The task IDs are the\\nsame as in Table 2. The scores in the table are the average scores over three trials. The values in parentheses\\nrepresent the standard deviation.\\n16'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0]['method']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5894a834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af11db87",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = json.load(open(\"llm_prompt_optimization_engineering.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4390dd88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a572f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "380c5cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c95dcf9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>tag</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>published</th>\n",
       "      <th>summary</th>\n",
       "      <th>link</th>\n",
       "      <th>pdf_link</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>llm%20prompt%20optimization%20engineering</td>\n",
       "      <td>The Prompt Alchemist: Automated LLM-Tailored P...</td>\n",
       "      <td>Shuzheng Gao, Chaozheng Wang, Cuiyun Gao, Xiao...</td>\n",
       "      <td>2025-01-02T16:30:05Z</td>\n",
       "      <td>Test cases are essential for validating the re...</td>\n",
       "      <td>http://arxiv.org/abs/2501.01329v1</td>\n",
       "      <td>http://arxiv.org/pdf/2501.01329v1.pdf</td>\n",
       "      <td>2501.01329v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>llm%20prompt%20optimization%20engineering</td>\n",
       "      <td>DDPT: Diffusion-Driven Prompt Tuning for Large...</td>\n",
       "      <td>Jinyang Li, Sangwon Hyun, M. Ali Babar</td>\n",
       "      <td>2025-04-06T04:19:19Z</td>\n",
       "      <td>Large Language Models (LLMs) have demonstrated...</td>\n",
       "      <td>http://arxiv.org/abs/2504.04351v1</td>\n",
       "      <td>http://arxiv.org/pdf/2504.04351v1.pdf</td>\n",
       "      <td>2504.04351v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>llm%20prompt%20optimization%20engineering</td>\n",
       "      <td>Bandit-Based Prompt Design Strategy Selection ...</td>\n",
       "      <td>Rin Ashizawa, Yoichi Hirose, Nozomu Yoshinari,...</td>\n",
       "      <td>2025-03-03T04:24:04Z</td>\n",
       "      <td>Prompt optimization aims to search for effecti...</td>\n",
       "      <td>http://arxiv.org/abs/2503.01163v1</td>\n",
       "      <td>http://arxiv.org/pdf/2503.01163v1.pdf</td>\n",
       "      <td>2503.01163v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>llm%20prompt%20optimization%20engineering</td>\n",
       "      <td>Joint Optimization of Prompt Security and Syst...</td>\n",
       "      <td>Haiyang Huang, Tianhui Meng, Weijia Jia</td>\n",
       "      <td>2025-01-30T14:33:49Z</td>\n",
       "      <td>Large language models (LLMs) have significantl...</td>\n",
       "      <td>http://arxiv.org/abs/2501.18663v1</td>\n",
       "      <td>http://arxiv.org/pdf/2501.18663v1.pdf</td>\n",
       "      <td>2501.18663v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>llm%20prompt%20optimization%20engineering</td>\n",
       "      <td>APEER: Automatic Prompt Engineering Enhances L...</td>\n",
       "      <td>Can Jin, Hongwu Peng, Shiyu Zhao, Zhenting Wan...</td>\n",
       "      <td>2024-06-20T16:11:45Z</td>\n",
       "      <td>Large Language Models (LLMs) have significantl...</td>\n",
       "      <td>http://arxiv.org/abs/2406.14449v1</td>\n",
       "      <td>http://arxiv.org/pdf/2406.14449v1.pdf</td>\n",
       "      <td>2406.14449v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>3195</td>\n",
       "      <td>llm%20prompt%20optimization%20engineering</td>\n",
       "      <td>Co-Learning: Code Learning for Multi-Agent Rei...</td>\n",
       "      <td>Jiapeng Yu, Yuqian Wu, Yajing Zhan, Wenhao Guo...</td>\n",
       "      <td>2024-09-02T07:03:22Z</td>\n",
       "      <td>Online question-and-answer (Q\\&amp;A) systems base...</td>\n",
       "      <td>http://arxiv.org/abs/2409.00985v1</td>\n",
       "      <td>http://arxiv.org/pdf/2409.00985v1.pdf</td>\n",
       "      <td>2409.00985v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>3196</td>\n",
       "      <td>llm%20prompt%20optimization%20engineering</td>\n",
       "      <td>Green My LLM: Studying the key factors affecti...</td>\n",
       "      <td>Tristan Coignion, Clément Quinton, Romain Rouvoy</td>\n",
       "      <td>2024-11-07T16:00:29Z</td>\n",
       "      <td>In recent years,Large Language Models (LLMs) h...</td>\n",
       "      <td>http://arxiv.org/abs/2411.11892v1</td>\n",
       "      <td>http://arxiv.org/pdf/2411.11892v1.pdf</td>\n",
       "      <td>2411.11892v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>3197</td>\n",
       "      <td>llm%20prompt%20optimization%20engineering</td>\n",
       "      <td>A Survey of Sustainability in Large Language M...</td>\n",
       "      <td>Aditi Singh, Nirmal Prakashbhai Patel, Abul Eh...</td>\n",
       "      <td>2024-12-06T05:20:04Z</td>\n",
       "      <td>Large Language Models (LLMs) have transformed ...</td>\n",
       "      <td>http://arxiv.org/abs/2412.04782v2</td>\n",
       "      <td>http://arxiv.org/pdf/2412.04782v2.pdf</td>\n",
       "      <td>2412.04782v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>3198</td>\n",
       "      <td>llm%20prompt%20optimization%20engineering</td>\n",
       "      <td>ContextModule: Improving Code Completion via R...</td>\n",
       "      <td>Zhanming Guan, Junlin Liu, Jierui Liu, Chao Pe...</td>\n",
       "      <td>2024-12-11T03:15:49Z</td>\n",
       "      <td>Large Language Models (LLMs) have demonstrated...</td>\n",
       "      <td>http://arxiv.org/abs/2412.08063v1</td>\n",
       "      <td>http://arxiv.org/pdf/2412.08063v1.pdf</td>\n",
       "      <td>2412.08063v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>3199</td>\n",
       "      <td>llm%20prompt%20optimization%20engineering</td>\n",
       "      <td>Generative AI Toolkit -- a framework for incre...</td>\n",
       "      <td>Jens Kohl, Luisa Gloger, Rui Costa, Otto Kruse...</td>\n",
       "      <td>2024-12-18T10:40:00Z</td>\n",
       "      <td>As LLM-based applications reach millions of cu...</td>\n",
       "      <td>http://arxiv.org/abs/2412.14215v1</td>\n",
       "      <td>http://arxiv.org/pdf/2412.14215v1.pdf</td>\n",
       "      <td>2412.14215v1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      paper_id                                        tag  \\\n",
       "0            0  llm%20prompt%20optimization%20engineering   \n",
       "1            1  llm%20prompt%20optimization%20engineering   \n",
       "2            2  llm%20prompt%20optimization%20engineering   \n",
       "3            3  llm%20prompt%20optimization%20engineering   \n",
       "4            4  llm%20prompt%20optimization%20engineering   \n",
       "...        ...                                        ...   \n",
       "3195      3195  llm%20prompt%20optimization%20engineering   \n",
       "3196      3196  llm%20prompt%20optimization%20engineering   \n",
       "3197      3197  llm%20prompt%20optimization%20engineering   \n",
       "3198      3198  llm%20prompt%20optimization%20engineering   \n",
       "3199      3199  llm%20prompt%20optimization%20engineering   \n",
       "\n",
       "                                                  title  \\\n",
       "0     The Prompt Alchemist: Automated LLM-Tailored P...   \n",
       "1     DDPT: Diffusion-Driven Prompt Tuning for Large...   \n",
       "2     Bandit-Based Prompt Design Strategy Selection ...   \n",
       "3     Joint Optimization of Prompt Security and Syst...   \n",
       "4     APEER: Automatic Prompt Engineering Enhances L...   \n",
       "...                                                 ...   \n",
       "3195  Co-Learning: Code Learning for Multi-Agent Rei...   \n",
       "3196  Green My LLM: Studying the key factors affecti...   \n",
       "3197  A Survey of Sustainability in Large Language M...   \n",
       "3198  ContextModule: Improving Code Completion via R...   \n",
       "3199  Generative AI Toolkit -- a framework for incre...   \n",
       "\n",
       "                                                authors             published  \\\n",
       "0     Shuzheng Gao, Chaozheng Wang, Cuiyun Gao, Xiao...  2025-01-02T16:30:05Z   \n",
       "1                Jinyang Li, Sangwon Hyun, M. Ali Babar  2025-04-06T04:19:19Z   \n",
       "2     Rin Ashizawa, Yoichi Hirose, Nozomu Yoshinari,...  2025-03-03T04:24:04Z   \n",
       "3               Haiyang Huang, Tianhui Meng, Weijia Jia  2025-01-30T14:33:49Z   \n",
       "4     Can Jin, Hongwu Peng, Shiyu Zhao, Zhenting Wan...  2024-06-20T16:11:45Z   \n",
       "...                                                 ...                   ...   \n",
       "3195  Jiapeng Yu, Yuqian Wu, Yajing Zhan, Wenhao Guo...  2024-09-02T07:03:22Z   \n",
       "3196   Tristan Coignion, Clément Quinton, Romain Rouvoy  2024-11-07T16:00:29Z   \n",
       "3197  Aditi Singh, Nirmal Prakashbhai Patel, Abul Eh...  2024-12-06T05:20:04Z   \n",
       "3198  Zhanming Guan, Junlin Liu, Jierui Liu, Chao Pe...  2024-12-11T03:15:49Z   \n",
       "3199  Jens Kohl, Luisa Gloger, Rui Costa, Otto Kruse...  2024-12-18T10:40:00Z   \n",
       "\n",
       "                                                summary  \\\n",
       "0     Test cases are essential for validating the re...   \n",
       "1     Large Language Models (LLMs) have demonstrated...   \n",
       "2     Prompt optimization aims to search for effecti...   \n",
       "3     Large language models (LLMs) have significantl...   \n",
       "4     Large Language Models (LLMs) have significantl...   \n",
       "...                                                 ...   \n",
       "3195  Online question-and-answer (Q\\&A) systems base...   \n",
       "3196  In recent years,Large Language Models (LLMs) h...   \n",
       "3197  Large Language Models (LLMs) have transformed ...   \n",
       "3198  Large Language Models (LLMs) have demonstrated...   \n",
       "3199  As LLM-based applications reach millions of cu...   \n",
       "\n",
       "                                   link  \\\n",
       "0     http://arxiv.org/abs/2501.01329v1   \n",
       "1     http://arxiv.org/abs/2504.04351v1   \n",
       "2     http://arxiv.org/abs/2503.01163v1   \n",
       "3     http://arxiv.org/abs/2501.18663v1   \n",
       "4     http://arxiv.org/abs/2406.14449v1   \n",
       "...                                 ...   \n",
       "3195  http://arxiv.org/abs/2409.00985v1   \n",
       "3196  http://arxiv.org/abs/2411.11892v1   \n",
       "3197  http://arxiv.org/abs/2412.04782v2   \n",
       "3198  http://arxiv.org/abs/2412.08063v1   \n",
       "3199  http://arxiv.org/abs/2412.14215v1   \n",
       "\n",
       "                                   pdf_link            id  \n",
       "0     http://arxiv.org/pdf/2501.01329v1.pdf  2501.01329v1  \n",
       "1     http://arxiv.org/pdf/2504.04351v1.pdf  2504.04351v1  \n",
       "2     http://arxiv.org/pdf/2503.01163v1.pdf  2503.01163v1  \n",
       "3     http://arxiv.org/pdf/2501.18663v1.pdf  2501.18663v1  \n",
       "4     http://arxiv.org/pdf/2406.14449v1.pdf  2406.14449v1  \n",
       "...                                     ...           ...  \n",
       "3195  http://arxiv.org/pdf/2409.00985v1.pdf  2409.00985v1  \n",
       "3196  http://arxiv.org/pdf/2411.11892v1.pdf  2411.11892v1  \n",
       "3197  http://arxiv.org/pdf/2412.04782v2.pdf  2412.04782v2  \n",
       "3198  http://arxiv.org/pdf/2412.08063v1.pdf  2412.08063v1  \n",
       "3199  http://arxiv.org/pdf/2412.14215v1.pdf  2412.14215v1  \n",
       "\n",
       "[3200 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb8b7b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Test cases are essential for validating the reliability and quality of software applications. Recent studies have demonstrated the capability of Large Language Models (LLMs) to generate useful test cases for given source code. However, the existing work primarily relies on human-written plain prompts, which often leads to suboptimal results since the performance of LLMs can be highly influenced by the prompts. Moreover, these approaches use the same prompt for all LLMs, overlooking the fact that different LLMs might be best suited to different prompts. Given the wide variety of possible prompt formulations, automatically discovering the optimal prompt for each LLM presents a significant challenge. Although there are methods on automated prompt optimization in the natural language processing field, they are hard to produce effective prompts for the test case generation task. First, the methods iteratively optimize prompts by simply combining and mutating existing ones without proper guidance, resulting in prompts that lack diversity and tend to repeat the same errors in the generated test cases. Second, the prompts are generally lack of domain contextual knowledge, limiting LLMs' performance in the task.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['summary'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "449aebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/aashrith/Downloads/fin_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "364606a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>tag</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>published</th>\n",
       "      <th>summary</th>\n",
       "      <th>link</th>\n",
       "      <th>pdf_link</th>\n",
       "      <th>id</th>\n",
       "      <th>problem_solution</th>\n",
       "      <th>problem</th>\n",
       "      <th>approach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>llm%20prompt%20optimization%20engineering</td>\n",
       "      <td>The Prompt Alchemist: Automated LLM-Tailored P...</td>\n",
       "      <td>Shuzheng Gao, Chaozheng Wang, Cuiyun Gao, Xiao...</td>\n",
       "      <td>2025-01-02T16:30:05Z</td>\n",
       "      <td>Test cases are essential for validating the re...</td>\n",
       "      <td>http://arxiv.org/abs/2501.01329v1</td>\n",
       "      <td>http://arxiv.org/pdf/2501.01329v1.pdf</td>\n",
       "      <td>2501.01329v1</td>\n",
       "      <td>\\n{\\n  \"problem\": \"Existing test case generat...</td>\n",
       "      <td>Existing test case generation methods for Larg...</td>\n",
       "      <td>Develop an automated prompt optimization metho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>llm%20prompt%20optimization%20engineering</td>\n",
       "      <td>DDPT: Diffusion-Driven Prompt Tuning for Large...</td>\n",
       "      <td>Jinyang Li, Sangwon Hyun, M. Ali Babar</td>\n",
       "      <td>2025-04-06T04:19:19Z</td>\n",
       "      <td>Large Language Models (LLMs) have demonstrated...</td>\n",
       "      <td>http://arxiv.org/abs/2504.04351v1</td>\n",
       "      <td>http://arxiv.org/pdf/2504.04351v1.pdf</td>\n",
       "      <td>2504.04351v1</td>\n",
       "      <td>\\n{\\n  \"problem\": \"LLMs have demonstrated rem...</td>\n",
       "      <td>LLMs have demonstrated remarkable capabilities...</td>\n",
       "      <td>Diffusion-Driven Prompt Tuning (DDPT) that lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>llm%20prompt%20optimization%20engineering</td>\n",
       "      <td>Bandit-Based Prompt Design Strategy Selection ...</td>\n",
       "      <td>Rin Ashizawa, Yoichi Hirose, Nozomu Yoshinari,...</td>\n",
       "      <td>2025-03-03T04:24:04Z</td>\n",
       "      <td>Prompt optimization aims to search for effecti...</td>\n",
       "      <td>http://arxiv.org/abs/2503.01163v1</td>\n",
       "      <td>http://arxiv.org/pdf/2503.01163v1.pdf</td>\n",
       "      <td>2503.01163v1</td>\n",
       "      <td>\\n{\\n  \"problem\": \"Existing prompt optimizati...</td>\n",
       "      <td>Existing prompt optimization methods often rel...</td>\n",
       "      <td>Introduce Optimizing Prompts with sTrategy Sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>llm%20prompt%20optimization%20engineering</td>\n",
       "      <td>Joint Optimization of Prompt Security and Syst...</td>\n",
       "      <td>Haiyang Huang, Tianhui Meng, Weijia Jia</td>\n",
       "      <td>2025-01-30T14:33:49Z</td>\n",
       "      <td>Large language models (LLMs) have significantl...</td>\n",
       "      <td>http://arxiv.org/abs/2501.18663v1</td>\n",
       "      <td>http://arxiv.org/pdf/2501.18663v1.pdf</td>\n",
       "      <td>2501.18663v1</td>\n",
       "      <td>\\n{\\n  \"problem\": \"Large language models (LLM...</td>\n",
       "      <td>Large language models (LLMs) have significantl...</td>\n",
       "      <td>Propose a vector-database-enabled lightweight ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>llm%20prompt%20optimization%20engineering</td>\n",
       "      <td>APEER: Automatic Prompt Engineering Enhances L...</td>\n",
       "      <td>Can Jin, Hongwu Peng, Shiyu Zhao, Zhenting Wan...</td>\n",
       "      <td>2024-06-20T16:11:45Z</td>\n",
       "      <td>Large Language Models (LLMs) have significantl...</td>\n",
       "      <td>http://arxiv.org/abs/2406.14449v1</td>\n",
       "      <td>http://arxiv.org/pdf/2406.14449v1.pdf</td>\n",
       "      <td>2406.14449v1</td>\n",
       "      <td>\\n{\\n  \"problem\": \"Current automatic prompt e...</td>\n",
       "      <td>Current automatic prompt engineering algorithm...</td>\n",
       "      <td>Introduce APEER, a novel automatic prompt engi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  paper_id                                        tag  \\\n",
       "0           0         0  llm%20prompt%20optimization%20engineering   \n",
       "1           1         1  llm%20prompt%20optimization%20engineering   \n",
       "2           2         2  llm%20prompt%20optimization%20engineering   \n",
       "3           3         3  llm%20prompt%20optimization%20engineering   \n",
       "4           4         4  llm%20prompt%20optimization%20engineering   \n",
       "\n",
       "                                               title  \\\n",
       "0  The Prompt Alchemist: Automated LLM-Tailored P...   \n",
       "1  DDPT: Diffusion-Driven Prompt Tuning for Large...   \n",
       "2  Bandit-Based Prompt Design Strategy Selection ...   \n",
       "3  Joint Optimization of Prompt Security and Syst...   \n",
       "4  APEER: Automatic Prompt Engineering Enhances L...   \n",
       "\n",
       "                                             authors             published  \\\n",
       "0  Shuzheng Gao, Chaozheng Wang, Cuiyun Gao, Xiao...  2025-01-02T16:30:05Z   \n",
       "1             Jinyang Li, Sangwon Hyun, M. Ali Babar  2025-04-06T04:19:19Z   \n",
       "2  Rin Ashizawa, Yoichi Hirose, Nozomu Yoshinari,...  2025-03-03T04:24:04Z   \n",
       "3            Haiyang Huang, Tianhui Meng, Weijia Jia  2025-01-30T14:33:49Z   \n",
       "4  Can Jin, Hongwu Peng, Shiyu Zhao, Zhenting Wan...  2024-06-20T16:11:45Z   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Test cases are essential for validating the re...   \n",
       "1  Large Language Models (LLMs) have demonstrated...   \n",
       "2  Prompt optimization aims to search for effecti...   \n",
       "3  Large language models (LLMs) have significantl...   \n",
       "4  Large Language Models (LLMs) have significantl...   \n",
       "\n",
       "                                link                               pdf_link  \\\n",
       "0  http://arxiv.org/abs/2501.01329v1  http://arxiv.org/pdf/2501.01329v1.pdf   \n",
       "1  http://arxiv.org/abs/2504.04351v1  http://arxiv.org/pdf/2504.04351v1.pdf   \n",
       "2  http://arxiv.org/abs/2503.01163v1  http://arxiv.org/pdf/2503.01163v1.pdf   \n",
       "3  http://arxiv.org/abs/2501.18663v1  http://arxiv.org/pdf/2501.18663v1.pdf   \n",
       "4  http://arxiv.org/abs/2406.14449v1  http://arxiv.org/pdf/2406.14449v1.pdf   \n",
       "\n",
       "             id                                   problem_solution  \\\n",
       "0  2501.01329v1   \\n{\\n  \"problem\": \"Existing test case generat...   \n",
       "1  2504.04351v1   \\n{\\n  \"problem\": \"LLMs have demonstrated rem...   \n",
       "2  2503.01163v1   \\n{\\n  \"problem\": \"Existing prompt optimizati...   \n",
       "3  2501.18663v1   \\n{\\n  \"problem\": \"Large language models (LLM...   \n",
       "4  2406.14449v1   \\n{\\n  \"problem\": \"Current automatic prompt e...   \n",
       "\n",
       "                                             problem  \\\n",
       "0  Existing test case generation methods for Larg...   \n",
       "1  LLMs have demonstrated remarkable capabilities...   \n",
       "2  Existing prompt optimization methods often rel...   \n",
       "3  Large language models (LLMs) have significantl...   \n",
       "4  Current automatic prompt engineering algorithm...   \n",
       "\n",
       "                                            approach  \n",
       "0  Develop an automated prompt optimization metho...  \n",
       "1  Diffusion-Driven Prompt Tuning (DDPT) that lea...  \n",
       "2  Introduce Optimizing Prompts with sTrategy Sel...  \n",
       "3  Propose a vector-database-enabled lightweight ...  \n",
       "4  Introduce APEER, a novel automatic prompt engi...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78d227b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "{\n",
      "  \"problem\": \"Existing test case generation methods for Large Language Models (LLMs) rely on human-written plain prompts, which can lead to suboptimal results due to the influence of prompts on LLM performance.\",\n",
      "  \"approach\": \"Develop an automated prompt optimization method that incorporates domain contextual knowledge and promotes diversity in prompts to improve the quality of generated test cases.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(df['problem_solution'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62a56d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0742c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold cross validation\n",
    "# rogue, meteor, bleu\n",
    "# models : 1B models\n",
    "# training: LoRA, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bef729ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df[df['problem'].isna()].index\n",
    "b = df[df['approach'].isna()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a520332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a==b).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8bd278ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3120"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['problem'].notna()]\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f0aa2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dataset_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51d78c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2808.0, 312.0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df) * 0.9, len(df) * 0.1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
